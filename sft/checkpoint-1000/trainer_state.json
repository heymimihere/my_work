{
  "best_metric": 1.044925332069397,
  "best_model_checkpoint": "../../saves/LLaMA3-8B/lora/sft/checkpoint-1000",
  "epoch": 2.962962962962963,
  "eval_steps": 100,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02962962962962963,
      "grad_norm": 0.8387923240661621,
      "learning_rate": 2.5e-05,
      "loss": 2.1342,
      "step": 10
    },
    {
      "epoch": 0.05925925925925926,
      "grad_norm": 1.0534054040908813,
      "learning_rate": 5e-05,
      "loss": 2.0605,
      "step": 20
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.8400360345840454,
      "learning_rate": 4.998743894613156e-05,
      "loss": 1.8742,
      "step": 30
    },
    {
      "epoch": 0.11851851851851852,
      "grad_norm": 1.1511406898498535,
      "learning_rate": 4.9949768406932165e-05,
      "loss": 1.6962,
      "step": 40
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.7232136130332947,
      "learning_rate": 4.9887026236935596e-05,
      "loss": 1.5739,
      "step": 50
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.7505798935890198,
      "learning_rate": 4.979927548476402e-05,
      "loss": 1.4364,
      "step": 60
    },
    {
      "epoch": 0.2074074074074074,
      "grad_norm": 0.8336140513420105,
      "learning_rate": 4.9686604329771445e-05,
      "loss": 1.3916,
      "step": 70
    },
    {
      "epoch": 0.23703703703703705,
      "grad_norm": 0.8102992177009583,
      "learning_rate": 4.9549125993433646e-05,
      "loss": 1.3592,
      "step": 80
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.9087554812431335,
      "learning_rate": 4.938697862557371e-05,
      "loss": 1.3129,
      "step": 90
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 1.0538341999053955,
      "learning_rate": 4.9200325165537416e-05,
      "loss": 1.3069,
      "step": 100
    },
    {
      "epoch": 0.2962962962962963,
      "eval_loss": 1.2734469175338745,
      "eval_runtime": 25.5244,
      "eval_samples_per_second": 11.753,
      "eval_steps_per_second": 11.753,
      "step": 100
    },
    {
      "epoch": 0.32592592592592595,
      "grad_norm": 0.9354398250579834,
      "learning_rate": 4.8989353178458065e-05,
      "loss": 1.2861,
      "step": 110
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.0323487520217896,
      "learning_rate": 4.875427466677521e-05,
      "loss": 1.2548,
      "step": 120
    },
    {
      "epoch": 0.3851851851851852,
      "grad_norm": 1.0200934410095215,
      "learning_rate": 4.8495325857196744e-05,
      "loss": 1.2483,
      "step": 130
    },
    {
      "epoch": 0.4148148148148148,
      "grad_norm": 1.1508774757385254,
      "learning_rate": 4.821276696331836e-05,
      "loss": 1.2133,
      "step": 140
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 1.0344635248184204,
      "learning_rate": 4.790688192413902e-05,
      "loss": 1.229,
      "step": 150
    },
    {
      "epoch": 0.4740740740740741,
      "grad_norm": 1.0817162990570068,
      "learning_rate": 4.757797811873511e-05,
      "loss": 1.2368,
      "step": 160
    },
    {
      "epoch": 0.5037037037037037,
      "grad_norm": 1.3167846202850342,
      "learning_rate": 4.722638605738e-05,
      "loss": 1.2146,
      "step": 170
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.2524189949035645,
      "learning_rate": 4.6852459049419474e-05,
      "loss": 1.2016,
      "step": 180
    },
    {
      "epoch": 0.562962962962963,
      "grad_norm": 1.254673957824707,
      "learning_rate": 4.645657284823673e-05,
      "loss": 1.1855,
      "step": 190
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 1.3861726522445679,
      "learning_rate": 4.603912527366368e-05,
      "loss": 1.2042,
      "step": 200
    },
    {
      "epoch": 0.5925925925925926,
      "eval_loss": 1.1647605895996094,
      "eval_runtime": 25.4393,
      "eval_samples_per_second": 11.793,
      "eval_steps_per_second": 11.793,
      "step": 200
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.364107370376587,
      "learning_rate": 4.5600535812218024e-05,
      "loss": 1.1492,
      "step": 210
    },
    {
      "epoch": 0.6518518518518519,
      "grad_norm": 1.338132619857788,
      "learning_rate": 4.5141245195567884e-05,
      "loss": 1.1819,
      "step": 220
    },
    {
      "epoch": 0.6814814814814815,
      "grad_norm": 1.3150248527526855,
      "learning_rate": 4.466171495764742e-05,
      "loss": 1.1578,
      "step": 230
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.313516616821289,
      "learning_rate": 4.416242697086863e-05,
      "loss": 1.1608,
      "step": 240
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 1.5246702432632446,
      "learning_rate": 4.364388296189534e-05,
      "loss": 1.1839,
      "step": 250
    },
    {
      "epoch": 0.7703703703703704,
      "grad_norm": 1.3419042825698853,
      "learning_rate": 4.310660400746594e-05,
      "loss": 1.1533,
      "step": 260
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4083417654037476,
      "learning_rate": 4.255113001077156e-05,
      "loss": 1.1318,
      "step": 270
    },
    {
      "epoch": 0.8296296296296296,
      "grad_norm": 1.401456594467163,
      "learning_rate": 4.197801915891577e-05,
      "loss": 1.1331,
      "step": 280
    },
    {
      "epoch": 0.8592592592592593,
      "grad_norm": 1.388484001159668,
      "learning_rate": 4.1387847362001227e-05,
      "loss": 1.1014,
      "step": 290
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.4133301973342896,
      "learning_rate": 4.0781207674406515e-05,
      "loss": 1.1168,
      "step": 300
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 1.1189548969268799,
      "eval_runtime": 25.5454,
      "eval_samples_per_second": 11.744,
      "eval_steps_per_second": 11.744,
      "step": 300
    },
    {
      "epoch": 0.9185185185185185,
      "grad_norm": 1.5081305503845215,
      "learning_rate": 4.0158709698835226e-05,
      "loss": 1.1116,
      "step": 310
    },
    {
      "epoch": 0.9481481481481482,
      "grad_norm": 1.6934640407562256,
      "learning_rate": 3.9520978973735676e-05,
      "loss": 1.0994,
      "step": 320
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.453173041343689,
      "learning_rate": 3.88686563447072e-05,
      "loss": 1.1246,
      "step": 330
    },
    {
      "epoch": 1.0074074074074073,
      "grad_norm": 1.4884740114212036,
      "learning_rate": 3.8202397320524407e-05,
      "loss": 1.1072,
      "step": 340
    },
    {
      "epoch": 1.037037037037037,
      "grad_norm": 1.6778970956802368,
      "learning_rate": 3.752287141442677e-05,
      "loss": 1.1324,
      "step": 350
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.6964107751846313,
      "learning_rate": 3.6830761471335176e-05,
      "loss": 1.0765,
      "step": 360
    },
    {
      "epoch": 1.0962962962962963,
      "grad_norm": 1.6236960887908936,
      "learning_rate": 3.612676298167191e-05,
      "loss": 1.1095,
      "step": 370
    },
    {
      "epoch": 1.125925925925926,
      "grad_norm": 1.7366491556167603,
      "learning_rate": 3.54115833824731e-05,
      "loss": 1.116,
      "step": 380
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 1.676509141921997,
      "learning_rate": 3.468594134649644e-05,
      "loss": 1.0837,
      "step": 390
    },
    {
      "epoch": 1.1851851851851851,
      "grad_norm": 1.6903170347213745,
      "learning_rate": 3.395056606003818e-05,
      "loss": 1.1041,
      "step": 400
    },
    {
      "epoch": 1.1851851851851851,
      "eval_loss": 1.092734932899475,
      "eval_runtime": 25.5822,
      "eval_samples_per_second": 11.727,
      "eval_steps_per_second": 11.727,
      "step": 400
    },
    {
      "epoch": 1.2148148148148148,
      "grad_norm": 1.5703158378601074,
      "learning_rate": 3.3206196490185274e-05,
      "loss": 1.0901,
      "step": 410
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 1.7808932065963745,
      "learning_rate": 3.24535806422389e-05,
      "loss": 1.0761,
      "step": 420
    },
    {
      "epoch": 1.2740740740740741,
      "grad_norm": 1.7719931602478027,
      "learning_rate": 3.1693474808055736e-05,
      "loss": 1.0895,
      "step": 430
    },
    {
      "epoch": 1.3037037037037038,
      "grad_norm": 1.7075450420379639,
      "learning_rate": 3.092664280606209e-05,
      "loss": 1.0771,
      "step": 440
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.8180193901062012,
      "learning_rate": 3.0153855213704755e-05,
      "loss": 1.0915,
      "step": 450
    },
    {
      "epoch": 1.362962962962963,
      "grad_norm": 1.7185330390930176,
      "learning_rate": 2.937588859310987e-05,
      "loss": 1.0772,
      "step": 460
    },
    {
      "epoch": 1.3925925925925926,
      "grad_norm": 1.715011715888977,
      "learning_rate": 2.8593524710727744e-05,
      "loss": 1.073,
      "step": 470
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 1.8718113899230957,
      "learning_rate": 2.7807549751748095e-05,
      "loss": 1.0541,
      "step": 480
    },
    {
      "epoch": 1.4518518518518517,
      "grad_norm": 1.8219090700149536,
      "learning_rate": 2.7018753530074846e-05,
      "loss": 1.1005,
      "step": 490
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 1.8062739372253418,
      "learning_rate": 2.6227928694654525e-05,
      "loss": 1.0738,
      "step": 500
    },
    {
      "epoch": 1.4814814814814814,
      "eval_loss": 1.074702262878418,
      "eval_runtime": 25.4537,
      "eval_samples_per_second": 11.786,
      "eval_steps_per_second": 11.786,
      "step": 500
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 1.7201744318008423,
      "learning_rate": 2.5435869932955797e-05,
      "loss": 1.0784,
      "step": 510
    },
    {
      "epoch": 1.5407407407407407,
      "grad_norm": 1.7527421712875366,
      "learning_rate": 2.4643373172400466e-05,
      "loss": 1.0637,
      "step": 520
    },
    {
      "epoch": 1.5703703703703704,
      "grad_norm": 1.7142716646194458,
      "learning_rate": 2.3851234780548527e-05,
      "loss": 1.0721,
      "step": 530
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.9407378435134888,
      "learning_rate": 2.306025076484088e-05,
      "loss": 1.0868,
      "step": 540
    },
    {
      "epoch": 1.6296296296296298,
      "grad_norm": 1.9950897693634033,
      "learning_rate": 2.2271215972703965e-05,
      "loss": 1.055,
      "step": 550
    },
    {
      "epoch": 1.6592592592592592,
      "grad_norm": 1.7708003520965576,
      "learning_rate": 2.148492329282004e-05,
      "loss": 1.07,
      "step": 560
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 1.8643189668655396,
      "learning_rate": 2.070216285836575e-05,
      "loss": 1.0726,
      "step": 570
    },
    {
      "epoch": 1.7185185185185186,
      "grad_norm": 1.8233015537261963,
      "learning_rate": 1.992372125301977e-05,
      "loss": 1.0614,
      "step": 580
    },
    {
      "epoch": 1.748148148148148,
      "grad_norm": 1.7973616123199463,
      "learning_rate": 1.9150380720537163e-05,
      "loss": 1.0678,
      "step": 590
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 2.071096897125244,
      "learning_rate": 1.8382918378684886e-05,
      "loss": 1.0479,
      "step": 600
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 1.060891032218933,
      "eval_runtime": 25.4193,
      "eval_samples_per_second": 11.802,
      "eval_steps_per_second": 11.802,
      "step": 600
    },
    {
      "epoch": 1.8074074074074074,
      "grad_norm": 1.8473913669586182,
      "learning_rate": 1.762210543832839e-05,
      "loss": 1.066,
      "step": 610
    },
    {
      "epoch": 1.837037037037037,
      "grad_norm": 2.0988576412200928,
      "learning_rate": 1.686870642845389e-05,
      "loss": 1.0816,
      "step": 620
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 1.8227014541625977,
      "learning_rate": 1.612347842790517e-05,
      "loss": 1.0573,
      "step": 630
    },
    {
      "epoch": 1.8962962962962964,
      "grad_norm": 1.8237112760543823,
      "learning_rate": 1.5387170304606968e-05,
      "loss": 1.0575,
      "step": 640
    },
    {
      "epoch": 1.925925925925926,
      "grad_norm": 1.977577567100525,
      "learning_rate": 1.4660521963039331e-05,
      "loss": 1.0618,
      "step": 650
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 1.827757477760315,
      "learning_rate": 1.3944263600719198e-05,
      "loss": 1.0598,
      "step": 660
    },
    {
      "epoch": 1.9851851851851852,
      "grad_norm": 1.8830963373184204,
      "learning_rate": 1.3239114974436411e-05,
      "loss": 1.0599,
      "step": 670
    },
    {
      "epoch": 2.0148148148148146,
      "grad_norm": 1.7620173692703247,
      "learning_rate": 1.254578467698136e-05,
      "loss": 1.0518,
      "step": 680
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 1.8329509496688843,
      "learning_rate": 1.1864969425091236e-05,
      "loss": 1.0362,
      "step": 690
    },
    {
      "epoch": 2.074074074074074,
      "grad_norm": 1.8516151905059814,
      "learning_rate": 1.1197353359330313e-05,
      "loss": 1.0585,
      "step": 700
    },
    {
      "epoch": 2.074074074074074,
      "eval_loss": 1.05210280418396,
      "eval_runtime": 25.4341,
      "eval_samples_per_second": 11.795,
      "eval_steps_per_second": 11.795,
      "step": 700
    },
    {
      "epoch": 2.1037037037037036,
      "grad_norm": 1.9806838035583496,
      "learning_rate": 1.0543607356607846e-05,
      "loss": 1.0832,
      "step": 710
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 1.8785749673843384,
      "learning_rate": 9.904388356024341e-06,
      "loss": 1.033,
      "step": 720
    },
    {
      "epoch": 2.162962962962963,
      "grad_norm": 1.8488620519638062,
      "learning_rate": 9.280338698723803e-06,
      "loss": 1.052,
      "step": 730
    },
    {
      "epoch": 2.1925925925925926,
      "grad_norm": 2.2938287258148193,
      "learning_rate": 8.672085482415193e-06,
      "loss": 1.0749,
      "step": 740
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 1.991008996963501,
      "learning_rate": 8.08023993121175e-06,
      "loss": 1.0231,
      "step": 750
    },
    {
      "epoch": 2.251851851851852,
      "grad_norm": 2.1284031867980957,
      "learning_rate": 7.505396781421536e-06,
      "loss": 1.0416,
      "step": 760
    },
    {
      "epoch": 2.2814814814814817,
      "grad_norm": 2.0317296981811523,
      "learning_rate": 6.948133683906172e-06,
      "loss": 1.041,
      "step": 770
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 1.823972463607788,
      "learning_rate": 6.409010623608594e-06,
      "loss": 1.018,
      "step": 780
    },
    {
      "epoch": 2.3407407407407406,
      "grad_norm": 1.999855399131775,
      "learning_rate": 5.8885693568329934e-06,
      "loss": 1.0395,
      "step": 790
    },
    {
      "epoch": 2.3703703703703702,
      "grad_norm": 1.9768552780151367,
      "learning_rate": 5.3873328668423316e-06,
      "loss": 1.0289,
      "step": 800
    },
    {
      "epoch": 2.3703703703703702,
      "eval_loss": 1.04737389087677,
      "eval_runtime": 25.5661,
      "eval_samples_per_second": 11.734,
      "eval_steps_per_second": 11.734,
      "step": 800
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.9880567789077759,
      "learning_rate": 4.9058048383207516e-06,
      "loss": 1.0386,
      "step": 810
    },
    {
      "epoch": 2.4296296296296296,
      "grad_norm": 1.8861631155014038,
      "learning_rate": 4.444469151228678e-06,
      "loss": 1.0169,
      "step": 820
    },
    {
      "epoch": 2.4592592592592593,
      "grad_norm": 2.06535267829895,
      "learning_rate": 4.003789394559485e-06,
      "loss": 1.0412,
      "step": 830
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 1.8596515655517578,
      "learning_rate": 3.5842084004861443e-06,
      "loss": 1.0499,
      "step": 840
    },
    {
      "epoch": 2.5185185185185186,
      "grad_norm": 2.0254266262054443,
      "learning_rate": 3.1861477993661543e-06,
      "loss": 1.0188,
      "step": 850
    },
    {
      "epoch": 2.5481481481481483,
      "grad_norm": 2.1116435527801514,
      "learning_rate": 2.8100075960518e-06,
      "loss": 1.0504,
      "step": 860
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 1.9323879480361938,
      "learning_rate": 2.4561657679315506e-06,
      "loss": 1.0211,
      "step": 870
    },
    {
      "epoch": 2.6074074074074076,
      "grad_norm": 2.0095369815826416,
      "learning_rate": 2.1249778851065327e-06,
      "loss": 1.0359,
      "step": 880
    },
    {
      "epoch": 2.637037037037037,
      "grad_norm": 2.076307773590088,
      "learning_rate": 1.8167767530836767e-06,
      "loss": 1.056,
      "step": 890
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 2.139410972595215,
      "learning_rate": 1.5318720783447232e-06,
      "loss": 1.0413,
      "step": 900
    },
    {
      "epoch": 2.6666666666666665,
      "eval_loss": 1.045324444770813,
      "eval_runtime": 25.4656,
      "eval_samples_per_second": 11.781,
      "eval_steps_per_second": 11.781,
      "step": 900
    },
    {
      "epoch": 2.696296296296296,
      "grad_norm": 2.003575563430786,
      "learning_rate": 1.2705501571269985e-06,
      "loss": 1.0584,
      "step": 910
    },
    {
      "epoch": 2.725925925925926,
      "grad_norm": 1.8393937349319458,
      "learning_rate": 1.0330735877288722e-06,
      "loss": 1.0085,
      "step": 920
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 2.086125135421753,
      "learning_rate": 8.196810066287919e-07,
      "loss": 1.0435,
      "step": 930
    },
    {
      "epoch": 2.785185185185185,
      "grad_norm": 2.0899713039398193,
      "learning_rate": 6.305868486832622e-07,
      "loss": 1.0192,
      "step": 940
    },
    {
      "epoch": 2.814814814814815,
      "grad_norm": 1.9676870107650757,
      "learning_rate": 4.6598113164462163e-07,
      "loss": 1.0519,
      "step": 950
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 1.9411734342575073,
      "learning_rate": 3.26029265215172e-07,
      "loss": 1.0438,
      "step": 960
    },
    {
      "epoch": 2.8740740740740742,
      "grad_norm": 1.8741333484649658,
      "learning_rate": 2.1087188482956656e-07,
      "loss": 1.0364,
      "step": 970
    },
    {
      "epoch": 2.9037037037037035,
      "grad_norm": 1.9527912139892578,
      "learning_rate": 1.206247103324759e-07,
      "loss": 1.0172,
      "step": 980
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 2.1679937839508057,
      "learning_rate": 5.537842969353113e-08,
      "loss": 1.0259,
      "step": 990
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 1.8104300498962402,
      "learning_rate": 1.519860787639049e-08,
      "loss": 1.048,
      "step": 1000
    },
    {
      "epoch": 2.962962962962963,
      "eval_loss": 1.044925332069397,
      "eval_runtime": 25.3971,
      "eval_samples_per_second": 11.812,
      "eval_steps_per_second": 11.812,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1011,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 2.1160667535428813e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
