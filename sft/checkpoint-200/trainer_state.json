{
  "best_metric": 1.1647605895996094,
  "best_model_checkpoint": "../../saves/LLaMA3-8B/lora/sft/checkpoint-200",
  "epoch": 0.5925925925925926,
  "eval_steps": 100,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02962962962962963,
      "grad_norm": 0.8387923240661621,
      "learning_rate": 2.5e-05,
      "loss": 2.1342,
      "step": 10
    },
    {
      "epoch": 0.05925925925925926,
      "grad_norm": 1.0534054040908813,
      "learning_rate": 5e-05,
      "loss": 2.0605,
      "step": 20
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.8400360345840454,
      "learning_rate": 4.998743894613156e-05,
      "loss": 1.8742,
      "step": 30
    },
    {
      "epoch": 0.11851851851851852,
      "grad_norm": 1.1511406898498535,
      "learning_rate": 4.9949768406932165e-05,
      "loss": 1.6962,
      "step": 40
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.7232136130332947,
      "learning_rate": 4.9887026236935596e-05,
      "loss": 1.5739,
      "step": 50
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.7505798935890198,
      "learning_rate": 4.979927548476402e-05,
      "loss": 1.4364,
      "step": 60
    },
    {
      "epoch": 0.2074074074074074,
      "grad_norm": 0.8336140513420105,
      "learning_rate": 4.9686604329771445e-05,
      "loss": 1.3916,
      "step": 70
    },
    {
      "epoch": 0.23703703703703705,
      "grad_norm": 0.8102992177009583,
      "learning_rate": 4.9549125993433646e-05,
      "loss": 1.3592,
      "step": 80
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.9087554812431335,
      "learning_rate": 4.938697862557371e-05,
      "loss": 1.3129,
      "step": 90
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 1.0538341999053955,
      "learning_rate": 4.9200325165537416e-05,
      "loss": 1.3069,
      "step": 100
    },
    {
      "epoch": 0.2962962962962963,
      "eval_loss": 1.2734469175338745,
      "eval_runtime": 25.5244,
      "eval_samples_per_second": 11.753,
      "eval_steps_per_second": 11.753,
      "step": 100
    },
    {
      "epoch": 0.32592592592592595,
      "grad_norm": 0.9354398250579834,
      "learning_rate": 4.8989353178458065e-05,
      "loss": 1.2861,
      "step": 110
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.0323487520217896,
      "learning_rate": 4.875427466677521e-05,
      "loss": 1.2548,
      "step": 120
    },
    {
      "epoch": 0.3851851851851852,
      "grad_norm": 1.0200934410095215,
      "learning_rate": 4.8495325857196744e-05,
      "loss": 1.2483,
      "step": 130
    },
    {
      "epoch": 0.4148148148148148,
      "grad_norm": 1.1508774757385254,
      "learning_rate": 4.821276696331836e-05,
      "loss": 1.2133,
      "step": 140
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 1.0344635248184204,
      "learning_rate": 4.790688192413902e-05,
      "loss": 1.229,
      "step": 150
    },
    {
      "epoch": 0.4740740740740741,
      "grad_norm": 1.0817162990570068,
      "learning_rate": 4.757797811873511e-05,
      "loss": 1.2368,
      "step": 160
    },
    {
      "epoch": 0.5037037037037037,
      "grad_norm": 1.3167846202850342,
      "learning_rate": 4.722638605738e-05,
      "loss": 1.2146,
      "step": 170
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.2524189949035645,
      "learning_rate": 4.6852459049419474e-05,
      "loss": 1.2016,
      "step": 180
    },
    {
      "epoch": 0.562962962962963,
      "grad_norm": 1.254673957824707,
      "learning_rate": 4.645657284823673e-05,
      "loss": 1.1855,
      "step": 190
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 1.3861726522445679,
      "learning_rate": 4.603912527366368e-05,
      "loss": 1.2042,
      "step": 200
    },
    {
      "epoch": 0.5925925925925926,
      "eval_loss": 1.1647605895996094,
      "eval_runtime": 25.4393,
      "eval_samples_per_second": 11.793,
      "eval_steps_per_second": 11.793,
      "step": 200
    }
  ],
  "logging_steps": 10,
  "max_steps": 1011,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 4.228788995437363e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
