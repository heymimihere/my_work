{
  "best_metric": 1.1189548969268799,
  "best_model_checkpoint": "../../saves/LLaMA3-8B/lora/sft/checkpoint-300",
  "epoch": 0.8888888888888888,
  "eval_steps": 100,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02962962962962963,
      "grad_norm": 0.8387923240661621,
      "learning_rate": 2.5e-05,
      "loss": 2.1342,
      "step": 10
    },
    {
      "epoch": 0.05925925925925926,
      "grad_norm": 1.0534054040908813,
      "learning_rate": 5e-05,
      "loss": 2.0605,
      "step": 20
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.8400360345840454,
      "learning_rate": 4.998743894613156e-05,
      "loss": 1.8742,
      "step": 30
    },
    {
      "epoch": 0.11851851851851852,
      "grad_norm": 1.1511406898498535,
      "learning_rate": 4.9949768406932165e-05,
      "loss": 1.6962,
      "step": 40
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 0.7232136130332947,
      "learning_rate": 4.9887026236935596e-05,
      "loss": 1.5739,
      "step": 50
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.7505798935890198,
      "learning_rate": 4.979927548476402e-05,
      "loss": 1.4364,
      "step": 60
    },
    {
      "epoch": 0.2074074074074074,
      "grad_norm": 0.8336140513420105,
      "learning_rate": 4.9686604329771445e-05,
      "loss": 1.3916,
      "step": 70
    },
    {
      "epoch": 0.23703703703703705,
      "grad_norm": 0.8102992177009583,
      "learning_rate": 4.9549125993433646e-05,
      "loss": 1.3592,
      "step": 80
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.9087554812431335,
      "learning_rate": 4.938697862557371e-05,
      "loss": 1.3129,
      "step": 90
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 1.0538341999053955,
      "learning_rate": 4.9200325165537416e-05,
      "loss": 1.3069,
      "step": 100
    },
    {
      "epoch": 0.2962962962962963,
      "eval_loss": 1.2734469175338745,
      "eval_runtime": 25.5244,
      "eval_samples_per_second": 11.753,
      "eval_steps_per_second": 11.753,
      "step": 100
    },
    {
      "epoch": 0.32592592592592595,
      "grad_norm": 0.9354398250579834,
      "learning_rate": 4.8989353178458065e-05,
      "loss": 1.2861,
      "step": 110
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.0323487520217896,
      "learning_rate": 4.875427466677521e-05,
      "loss": 1.2548,
      "step": 120
    },
    {
      "epoch": 0.3851851851851852,
      "grad_norm": 1.0200934410095215,
      "learning_rate": 4.8495325857196744e-05,
      "loss": 1.2483,
      "step": 130
    },
    {
      "epoch": 0.4148148148148148,
      "grad_norm": 1.1508774757385254,
      "learning_rate": 4.821276696331836e-05,
      "loss": 1.2133,
      "step": 140
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 1.0344635248184204,
      "learning_rate": 4.790688192413902e-05,
      "loss": 1.229,
      "step": 150
    },
    {
      "epoch": 0.4740740740740741,
      "grad_norm": 1.0817162990570068,
      "learning_rate": 4.757797811873511e-05,
      "loss": 1.2368,
      "step": 160
    },
    {
      "epoch": 0.5037037037037037,
      "grad_norm": 1.3167846202850342,
      "learning_rate": 4.722638605738e-05,
      "loss": 1.2146,
      "step": 170
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.2524189949035645,
      "learning_rate": 4.6852459049419474e-05,
      "loss": 1.2016,
      "step": 180
    },
    {
      "epoch": 0.562962962962963,
      "grad_norm": 1.254673957824707,
      "learning_rate": 4.645657284823673e-05,
      "loss": 1.1855,
      "step": 190
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 1.3861726522445679,
      "learning_rate": 4.603912527366368e-05,
      "loss": 1.2042,
      "step": 200
    },
    {
      "epoch": 0.5925925925925926,
      "eval_loss": 1.1647605895996094,
      "eval_runtime": 25.4393,
      "eval_samples_per_second": 11.793,
      "eval_steps_per_second": 11.793,
      "step": 200
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.364107370376587,
      "learning_rate": 4.5600535812218024e-05,
      "loss": 1.1492,
      "step": 210
    },
    {
      "epoch": 0.6518518518518519,
      "grad_norm": 1.338132619857788,
      "learning_rate": 4.5141245195567884e-05,
      "loss": 1.1819,
      "step": 220
    },
    {
      "epoch": 0.6814814814814815,
      "grad_norm": 1.3150248527526855,
      "learning_rate": 4.466171495764742e-05,
      "loss": 1.1578,
      "step": 230
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.313516616821289,
      "learning_rate": 4.416242697086863e-05,
      "loss": 1.1608,
      "step": 240
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 1.5246702432632446,
      "learning_rate": 4.364388296189534e-05,
      "loss": 1.1839,
      "step": 250
    },
    {
      "epoch": 0.7703703703703704,
      "grad_norm": 1.3419042825698853,
      "learning_rate": 4.310660400746594e-05,
      "loss": 1.1533,
      "step": 260
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4083417654037476,
      "learning_rate": 4.255113001077156e-05,
      "loss": 1.1318,
      "step": 270
    },
    {
      "epoch": 0.8296296296296296,
      "grad_norm": 1.401456594467163,
      "learning_rate": 4.197801915891577e-05,
      "loss": 1.1331,
      "step": 280
    },
    {
      "epoch": 0.8592592592592593,
      "grad_norm": 1.388484001159668,
      "learning_rate": 4.1387847362001227e-05,
      "loss": 1.1014,
      "step": 290
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.4133301973342896,
      "learning_rate": 4.0781207674406515e-05,
      "loss": 1.1168,
      "step": 300
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 1.1189548969268799,
      "eval_runtime": 25.5454,
      "eval_samples_per_second": 11.744,
      "eval_steps_per_second": 11.744,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 1011,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 6.353526972068659e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
